<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>5 Appendix A: Glossary | Course Notes - Introduction to Analytics Modeling</title>
  <meta name="description" content="Course notes for Introduction to Analytics Modeling (ISYE 6501)" />
  <meta name="generator" content="bookdown 0.40 and GitBook 2.6.7" />

  <meta property="og:title" content="5 Appendix A: Glossary | Course Notes - Introduction to Analytics Modeling" />
  <meta property="og:type" content="book" />
  
  <meta property="og:description" content="Course notes for Introduction to Analytics Modeling (ISYE 6501)" />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="5 Appendix A: Glossary | Course Notes - Introduction to Analytics Modeling" />
  
  <meta name="twitter:description" content="Course notes for Introduction to Analytics Modeling (ISYE 6501)" />
  

<meta name="author" content="Nolan MacDonald" />



  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="module-4---clustering.html"/>

<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>



<style type="text/css">
  
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
</style>
<style type="text/css">
/* Used with Pandoc 2.11+ new --citeproc when CSL is used */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>

</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li class="chapter" data-level="1" data-path="module-1---introduction.html"><a href="module-1---introduction.html"><i class="fa fa-check"></i><b>1</b> Module 1 - Introduction</a>
<ul>
<li class="chapter" data-level="1.1" data-path="module-1---introduction.html"><a href="module-1---introduction.html#m1l1---course-overview"><i class="fa fa-check"></i><b>1.1</b> M1L1 - Course Overview</a></li>
<li class="chapter" data-level="1.2" data-path="module-1---introduction.html"><a href="module-1---introduction.html#m1l2---course-structure"><i class="fa fa-check"></i><b>1.2</b> M1L2 - Course Structure</a></li>
<li class="chapter" data-level="1.3" data-path="module-1---introduction.html"><a href="module-1---introduction.html#m1l2a---homework-grading-and-qa"><i class="fa fa-check"></i><b>1.3</b> M1L2a - Homework Grading and Q&amp;A</a>
<ul>
<li class="chapter" data-level="1.3.1" data-path="module-1---introduction.html"><a href="module-1---introduction.html#homework-format"><i class="fa fa-check"></i><b>1.3.1</b> Homework Format</a></li>
<li class="chapter" data-level="1.3.2" data-path="module-1---introduction.html"><a href="module-1---introduction.html#grading-homeworks"><i class="fa fa-check"></i><b>1.3.2</b> Grading Homeworks</a></li>
</ul></li>
<li class="chapter" data-level="1.4" data-path="module-1---introduction.html"><a href="module-1---introduction.html#m1l3---modeling"><i class="fa fa-check"></i><b>1.4</b> M1L3 - Modeling</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="module-2---classification.html"><a href="module-2---classification.html"><i class="fa fa-check"></i><b>2</b> Module 2 - Classification</a>
<ul>
<li class="chapter" data-level="2.1" data-path="module-2---classification.html"><a href="module-2---classification.html#m2l1---introduction-to-classification"><i class="fa fa-check"></i><b>2.1</b> M2L1 - Introduction to Classification</a></li>
<li class="chapter" data-level="2.2" data-path="module-2---classification.html"><a href="module-2---classification.html#m2l2---choosing-a-classifier"><i class="fa fa-check"></i><b>2.2</b> M2L2 - Choosing a Classifier</a></li>
<li class="chapter" data-level="2.3" data-path="module-2---classification.html"><a href="module-2---classification.html#m2l3---data-definitions"><i class="fa fa-check"></i><b>2.3</b> M2L3 - Data Definitions</a></li>
<li class="chapter" data-level="2.4" data-path="module-2---classification.html"><a href="module-2---classification.html#m2l4---support-vector-machines-svms"><i class="fa fa-check"></i><b>2.4</b> M2L4 - Support Vector Machines (SVMs)</a></li>
<li class="chapter" data-level="2.5" data-path="module-2---classification.html"><a href="module-2---classification.html#m2l5---svm-what-the-name-means"><i class="fa fa-check"></i><b>2.5</b> M2L5 - SVM: What the Name Means</a></li>
<li class="chapter" data-level="2.6" data-path="module-2---classification.html"><a href="module-2---classification.html#m2l6---advanced-support-vector-machines"><i class="fa fa-check"></i><b>2.6</b> M2L6 - Advanced Support Vector Machines</a></li>
<li class="chapter" data-level="2.7" data-path="module-2---classification.html"><a href="module-2---classification.html#m2l7---scaling-and-standardization"><i class="fa fa-check"></i><b>2.7</b> M2L7 - Scaling and Standardization</a></li>
<li class="chapter" data-level="2.8" data-path="module-2---classification.html"><a href="module-2---classification.html#m2l8---k-nearest-neighbor-knn-algorithm"><i class="fa fa-check"></i><b>2.8</b> M2L8 - K-Nearest-Neighbor (KNN) Algorithm</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="module-3---validation.html"><a href="module-3---validation.html"><i class="fa fa-check"></i><b>3</b> Module 3 - Validation</a>
<ul>
<li class="chapter" data-level="3.1" data-path="module-3---validation.html"><a href="module-3---validation.html#overview"><i class="fa fa-check"></i><b>3.1</b> Overview</a></li>
<li class="chapter" data-level="3.2" data-path="module-3---validation.html"><a href="module-3---validation.html#m3l1---introduction-to-validation"><i class="fa fa-check"></i><b>3.2</b> M3L1 - Introduction to Validation</a>
<ul>
<li class="chapter" data-level="3.2.1" data-path="module-3---validation.html"><a href="module-3---validation.html#m3l1---summary"><i class="fa fa-check"></i><b>3.2.1</b> M3L1 - Summary</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="module-3---validation.html"><a href="module-3---validation.html#m3l2---validation-and-test-data-sets"><i class="fa fa-check"></i><b>3.3</b> M3L2 - Validation and Test Data Sets</a>
<ul>
<li class="chapter" data-level="3.3.1" data-path="module-3---validation.html"><a href="module-3---validation.html#summary"><i class="fa fa-check"></i><b>3.3.1</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="module-3---validation.html"><a href="module-3---validation.html#m3l3---splitting-data"><i class="fa fa-check"></i><b>3.4</b> M3L3 - Splitting Data</a>
<ul>
<li class="chapter" data-level="3.4.1" data-path="module-3---validation.html"><a href="module-3---validation.html#summary-1"><i class="fa fa-check"></i><b>3.4.1</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="3.5" data-path="module-3---validation.html"><a href="module-3---validation.html#m3l4---cross-validations"><i class="fa fa-check"></i><b>3.5</b> M3L4 - Cross-Validations</a>
<ul>
<li class="chapter" data-level="3.5.1" data-path="module-3---validation.html"><a href="module-3---validation.html#summary-2"><i class="fa fa-check"></i><b>3.5.1</b> Summary</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="module-4---clustering.html"><a href="module-4---clustering.html"><i class="fa fa-check"></i><b>4</b> Module 4 - Clustering</a>
<ul>
<li class="chapter" data-level="4.1" data-path="module-4---clustering.html"><a href="module-4---clustering.html#overview-1"><i class="fa fa-check"></i><b>4.1</b> Overview</a></li>
<li class="chapter" data-level="4.2" data-path="module-4---clustering.html"><a href="module-4---clustering.html#m4l1---introduction-to-clustering"><i class="fa fa-check"></i><b>4.2</b> M4L1 - Introduction to Clustering</a></li>
<li class="chapter" data-level="4.3" data-path="module-4---clustering.html"><a href="module-4---clustering.html#m4l2---distance-norms"><i class="fa fa-check"></i><b>4.3</b> M4L2 - Distance Norms</a></li>
<li class="chapter" data-level="4.4" data-path="module-4---clustering.html"><a href="module-4---clustering.html#m4l3---k-means-clustering"><i class="fa fa-check"></i><b>4.4</b> M4L3 - K-Means Clustering</a></li>
<li class="chapter" data-level="4.5" data-path="module-4---clustering.html"><a href="module-4---clustering.html#m4l4---practical-details-for-k-means"><i class="fa fa-check"></i><b>4.5</b> M4L4 - Practical Details for K-Means</a>
<ul>
<li class="chapter" data-level="4.5.1" data-path="module-4---clustering.html"><a href="module-4---clustering.html#summary-3"><i class="fa fa-check"></i><b>4.5.1</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="4.6" data-path="module-4---clustering.html"><a href="module-4---clustering.html#m4l5---clustering-for-prediction"><i class="fa fa-check"></i><b>4.6</b> M4L5 - Clustering for Prediction</a>
<ul>
<li class="chapter" data-level="4.6.1" data-path="module-4---clustering.html"><a href="module-4---clustering.html#summary-4"><i class="fa fa-check"></i><b>4.6.1</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="4.7" data-path="module-4---clustering.html"><a href="module-4---clustering.html#m4l6---clustering-v.-classification"><i class="fa fa-check"></i><b>4.7</b> M4L6 - Clustering v. Classification</a>
<ul>
<li class="chapter" data-level="4.7.1" data-path="module-4---clustering.html"><a href="module-4---clustering.html#summary-5"><i class="fa fa-check"></i><b>4.7.1</b> Summary</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="appendix-a-glossary.html"><a href="appendix-a-glossary.html"><i class="fa fa-check"></i><b>5</b> Appendix A: Glossary</a>
<ul>
<li class="chapter" data-level="5.1" data-path="appendix-a-glossary.html"><a href="appendix-a-glossary.html#basic-machine-learning"><i class="fa fa-check"></i><b>5.1</b> Basic Machine Learning</a></li>
</ul></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Course Notes - Introduction to Analytics Modeling</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="appendix-a-glossary" class="section level1 hasAnchor" number="5">
<h1><span class="header-section-number">5</span> Appendix A: Glossary<a href="appendix-a-glossary.html#appendix-a-glossary" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<div id="basic-machine-learning" class="section level2 hasAnchor" number="5.1">
<h2><span class="header-section-number">5.1</span> Basic Machine Learning<a href="appendix-a-glossary.html#basic-machine-learning" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p><em>Lessons 2.1-2.2, 2.4-2.6, 2.8, 4.1, 4.3-4.6, 6.1-6.3, 16.4</em></p>
<p><strong>Algorithm</strong>: Step-by-step procedure designed to carry out a task.</p>
<p><strong>Change detection</strong>: Identifying when a significant change has taken place in a process.</p>
<p><strong>Classification</strong>: The separation of data into two or more categories, or (a point‚Äôs classification) the category a data point is put into.</p>
<p><strong>Classifier</strong>: A boundary that separates the data into two or more categories. Also (more generally) an algorithm that performs classification.</p>
<p><strong>Cluster</strong>: A group of points identified as near/similar to each other.</p>
<p><strong>Cluster center</strong>: In some clustering algorithms (like ùëò-means clustering), the central point (often the centroid) of a cluster of data points.</p>
<p><strong>Clustering</strong>: Separation of data points into groups (‚Äúclusters‚Äù) based on nearness/similarity to each other. A common form of unsupervised learning.</p>
<p><strong>CUSUM</strong>: Change detection method that compares observed distribution mean with a threshold level of change. Short for ‚Äúcumulative sum‚Äù.</p>
<p><strong>Deep learning</strong>: Neural network-type model with many hidden layers.</p>
<p><strong>Dimension</strong>: A feature of the data points (for example, height or credit score). (Note that there is also a mathematical definition for this word.)</p>
<p><strong>EM algorithm</strong>: Expectation-maximization algorithm.</p>
<p><strong>Expectation-maximization algorithm (EM algorithm)</strong>: General description of an algorithm with two steps (often iterated), one that finds the function for the expected likelihood of getting the response given current parameters, and one that finds new parameter values to maximize that probability.</p>
<p><strong>Heuristic</strong>: Algorithm that is not guaranteed to find the absolute best (optimal) solution.</p>
<div style="page-break-after: always;"></div>
<p><strong>k-means algorithm</strong>: Clustering algorithm that defines ùëò clusters of data points, each corresponding to one of ùëò cluster centers selected by the algorithm.</p>
<p><strong>k-Nearest-Neighbor (KNN)</strong>: Classification algorithm that defines a data point‚Äôs category as a function of the nearest ùëò data points to it.</p>
<p><strong>Kernel</strong>: A type of function that computes the similarity between two inputs; thanks to what‚Äôs (really!) sometimes known as the ‚Äúkernel trick‚Äù, nonlinear classifiers can be found almost as easily as linear ones.</p>
<p><strong>Learning</strong>: Finding/discovering patterns (or rules) in data, often that can be applied to new data.</p>
<p><strong>Machine</strong>: Apparatus that can do something; in ‚Äúmachine learning‚Äù, it often refers to both an algorithm and the computer it‚Äôs run on. (Fun fact: before computers were developed, the term ‚Äúcomputers‚Äù referred to people who did calculations quickly in their heads or on paper!)</p>
<p><strong>Margin</strong>: For a single point, the distance between the point and the classification boundary; for a set of points, the minimum distance between a point in the set and the classification boundary. Also called the separation.</p>
<p><strong>Machine learning</strong>: Use of computer algorithms to learn and discover patterns or structure in data, without being programmed specifically for them.</p>
<p><strong>Misclassified</strong>: Put into the wrong category by a classifier.</p>
<p><strong>Neural network</strong>: A machine learning model that itself is modeled after the workings of neurons in the brain.</p>
<p><strong>Supervised learning</strong>: Machine learning where the ‚Äúcorrect‚Äù answer is known for each data point in the training set.</p>
<p><strong>Support vector</strong>: In SVM models, the closest point to the classifier, among those in a category. (Note that there is a more-technical mathematical definition too.)</p>
<p><strong>Support vector machine (SVM)</strong>: Classification algorithm that uses a boundary to separate the data into two or more categories (‚Äúclasses‚Äù).</p>
<p><strong>SVM</strong>: Support vector machine.</p>
<p><strong>Unsupervised learning</strong>: Machine learning where the ‚Äúcorrect‚Äù answer is not known for the data points in the training set.</p>
<p><strong>Voronoi diagram</strong>: Graphical representation of splitting a plane with two or more special points into regions with one special point each, where each region‚Äôs points are closest to that special point.</p>

<div id="refs" class="references csl-bib-body" entry-spacing="0">
<div class="csl-entry">
<div class="csl-left-margin">[1] </div><div class="csl-right-inline">S. Arlot and A. Celisse, <span>‚ÄúA survey of cross-validation procedures for model selection,‚Äù</span> 2010.</div>
</div>
<div class="csl-entry">
<div class="csl-left-margin">[2] </div><div class="csl-right-inline">Wikibooks, <span>‚ÄúData mining algorithms in r/clustering/k-means.‚Äù</span> <a href="http://en.wikipedia.org/w/index.php?title=K-means%20clustering&amp;oldid=1243054475" class="uri">http://en.wikipedia.org/w/index.php?title=K-means%20clustering&amp;oldid=1243054475</a>, 2024.</div>
</div>
</div>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="module-4---clustering.html" class="navigation navigation-prev navigation-unique" aria-label="Previous page"><i class="fa fa-angle-left"></i></a>

    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["ISYE6501-Notes-Fall2024.pdf"],
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
