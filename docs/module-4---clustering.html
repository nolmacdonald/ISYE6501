<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>4 Module 4 - Clustering | Course Notes - Introduction to Analytics Modeling</title>
  <meta name="description" content="Course notes for Introduction to Analytics Modeling (ISYE 6501)" />
  <meta name="generator" content="bookdown 0.40 and GitBook 2.6.7" />

  <meta property="og:title" content="4 Module 4 - Clustering | Course Notes - Introduction to Analytics Modeling" />
  <meta property="og:type" content="book" />
  
  <meta property="og:description" content="Course notes for Introduction to Analytics Modeling (ISYE 6501)" />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="4 Module 4 - Clustering | Course Notes - Introduction to Analytics Modeling" />
  
  <meta name="twitter:description" content="Course notes for Introduction to Analytics Modeling (ISYE 6501)" />
  

<meta name="author" content="Nolan MacDonald" />



  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="module-3---validation.html"/>
<link rel="next" href="module-5---basic-data-preparation.html"/>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>



<style type="text/css">
  
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
</style>
<style type="text/css">
/* Used with Pandoc 2.11+ new --citeproc when CSL is used */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>

</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li class="chapter" data-level="1" data-path="module-1---introduction.html"><a href="module-1---introduction.html"><i class="fa fa-check"></i><b>1</b> Module 1 - Introduction</a>
<ul>
<li class="chapter" data-level="1.1" data-path="module-1---introduction.html"><a href="module-1---introduction.html#m1l1---course-overview"><i class="fa fa-check"></i><b>1.1</b> M1L1 - Course Overview</a></li>
<li class="chapter" data-level="1.2" data-path="module-1---introduction.html"><a href="module-1---introduction.html#m1l2---course-structure"><i class="fa fa-check"></i><b>1.2</b> M1L2 - Course Structure</a></li>
<li class="chapter" data-level="1.3" data-path="module-1---introduction.html"><a href="module-1---introduction.html#m1l2a---homework-grading-and-qa"><i class="fa fa-check"></i><b>1.3</b> M1L2a - Homework Grading and Q&amp;A</a>
<ul>
<li class="chapter" data-level="1.3.1" data-path="module-1---introduction.html"><a href="module-1---introduction.html#homework-format"><i class="fa fa-check"></i><b>1.3.1</b> Homework Format</a></li>
<li class="chapter" data-level="1.3.2" data-path="module-1---introduction.html"><a href="module-1---introduction.html#grading-homeworks"><i class="fa fa-check"></i><b>1.3.2</b> Grading Homeworks</a></li>
</ul></li>
<li class="chapter" data-level="1.4" data-path="module-1---introduction.html"><a href="module-1---introduction.html#m1l3---modeling"><i class="fa fa-check"></i><b>1.4</b> M1L3 - Modeling</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="module-2---classification.html"><a href="module-2---classification.html"><i class="fa fa-check"></i><b>2</b> Module 2 - Classification</a>
<ul>
<li class="chapter" data-level="2.1" data-path="module-2---classification.html"><a href="module-2---classification.html#m2l1---introduction-to-classification"><i class="fa fa-check"></i><b>2.1</b> M2L1 - Introduction to Classification</a></li>
<li class="chapter" data-level="2.2" data-path="module-2---classification.html"><a href="module-2---classification.html#m2l2---choosing-a-classifier"><i class="fa fa-check"></i><b>2.2</b> M2L2 - Choosing a Classifier</a></li>
<li class="chapter" data-level="2.3" data-path="module-2---classification.html"><a href="module-2---classification.html#m2l3---data-definitions"><i class="fa fa-check"></i><b>2.3</b> M2L3 - Data Definitions</a></li>
<li class="chapter" data-level="2.4" data-path="module-2---classification.html"><a href="module-2---classification.html#m2l4---support-vector-machines-svms"><i class="fa fa-check"></i><b>2.4</b> M2L4 - Support Vector Machines (SVMs)</a></li>
<li class="chapter" data-level="2.5" data-path="module-2---classification.html"><a href="module-2---classification.html#m2l5---svm-what-the-name-means"><i class="fa fa-check"></i><b>2.5</b> M2L5 - SVM: What the Name Means</a></li>
<li class="chapter" data-level="2.6" data-path="module-2---classification.html"><a href="module-2---classification.html#m2l6---advanced-support-vector-machines"><i class="fa fa-check"></i><b>2.6</b> M2L6 - Advanced Support Vector Machines</a></li>
<li class="chapter" data-level="2.7" data-path="module-2---classification.html"><a href="module-2---classification.html#m2l7---scaling-and-standardization"><i class="fa fa-check"></i><b>2.7</b> M2L7 - Scaling and Standardization</a></li>
<li class="chapter" data-level="2.8" data-path="module-2---classification.html"><a href="module-2---classification.html#m2l8---k-nearest-neighbor-knn-algorithm"><i class="fa fa-check"></i><b>2.8</b> M2L8 - K-Nearest-Neighbor (KNN) Algorithm</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="module-3---validation.html"><a href="module-3---validation.html"><i class="fa fa-check"></i><b>3</b> Module 3 - Validation</a>
<ul>
<li class="chapter" data-level="3.1" data-path="module-3---validation.html"><a href="module-3---validation.html#overview"><i class="fa fa-check"></i><b>3.1</b> Overview</a></li>
<li class="chapter" data-level="3.2" data-path="module-3---validation.html"><a href="module-3---validation.html#m3l1---introduction-to-validation"><i class="fa fa-check"></i><b>3.2</b> M3L1 - Introduction to Validation</a>
<ul>
<li class="chapter" data-level="3.2.1" data-path="module-3---validation.html"><a href="module-3---validation.html#m3l1---summary"><i class="fa fa-check"></i><b>3.2.1</b> M3L1 - Summary</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="module-3---validation.html"><a href="module-3---validation.html#m3l2---validation-and-test-data-sets"><i class="fa fa-check"></i><b>3.3</b> M3L2 - Validation and Test Data Sets</a>
<ul>
<li class="chapter" data-level="3.3.1" data-path="module-3---validation.html"><a href="module-3---validation.html#summary"><i class="fa fa-check"></i><b>3.3.1</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="module-3---validation.html"><a href="module-3---validation.html#m3l3---splitting-data"><i class="fa fa-check"></i><b>3.4</b> M3L3 - Splitting Data</a>
<ul>
<li class="chapter" data-level="3.4.1" data-path="module-3---validation.html"><a href="module-3---validation.html#summary-1"><i class="fa fa-check"></i><b>3.4.1</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="3.5" data-path="module-3---validation.html"><a href="module-3---validation.html#m3l4---cross-validations"><i class="fa fa-check"></i><b>3.5</b> M3L4 - Cross-Validations</a>
<ul>
<li class="chapter" data-level="3.5.1" data-path="module-3---validation.html"><a href="module-3---validation.html#summary-2"><i class="fa fa-check"></i><b>3.5.1</b> Summary</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="module-4---clustering.html"><a href="module-4---clustering.html"><i class="fa fa-check"></i><b>4</b> Module 4 - Clustering</a>
<ul>
<li class="chapter" data-level="4.1" data-path="module-4---clustering.html"><a href="module-4---clustering.html#overview-1"><i class="fa fa-check"></i><b>4.1</b> Overview</a></li>
<li class="chapter" data-level="4.2" data-path="module-4---clustering.html"><a href="module-4---clustering.html#m4l1---introduction-to-clustering"><i class="fa fa-check"></i><b>4.2</b> M4L1 - Introduction to Clustering</a></li>
<li class="chapter" data-level="4.3" data-path="module-4---clustering.html"><a href="module-4---clustering.html#m4l2---distance-norms"><i class="fa fa-check"></i><b>4.3</b> M4L2 - Distance Norms</a></li>
<li class="chapter" data-level="4.4" data-path="module-4---clustering.html"><a href="module-4---clustering.html#m4l3---k-means-clustering"><i class="fa fa-check"></i><b>4.4</b> M4L3 - K-Means Clustering</a></li>
<li class="chapter" data-level="4.5" data-path="module-4---clustering.html"><a href="module-4---clustering.html#m4l4---practical-details-for-k-means"><i class="fa fa-check"></i><b>4.5</b> M4L4 - Practical Details for K-Means</a>
<ul>
<li class="chapter" data-level="4.5.1" data-path="module-4---clustering.html"><a href="module-4---clustering.html#summary-3"><i class="fa fa-check"></i><b>4.5.1</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="4.6" data-path="module-4---clustering.html"><a href="module-4---clustering.html#m4l5---clustering-for-prediction"><i class="fa fa-check"></i><b>4.6</b> M4L5 - Clustering for Prediction</a>
<ul>
<li class="chapter" data-level="4.6.1" data-path="module-4---clustering.html"><a href="module-4---clustering.html#summary-4"><i class="fa fa-check"></i><b>4.6.1</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="4.7" data-path="module-4---clustering.html"><a href="module-4---clustering.html#m4l6---clustering-v.-classification"><i class="fa fa-check"></i><b>4.7</b> M4L6 - Clustering v. Classification</a>
<ul>
<li class="chapter" data-level="4.7.1" data-path="module-4---clustering.html"><a href="module-4---clustering.html#summary-5"><i class="fa fa-check"></i><b>4.7.1</b> Summary</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="module-5---basic-data-preparation.html"><a href="module-5---basic-data-preparation.html"><i class="fa fa-check"></i><b>5</b> Module 5 - Basic Data Preparation</a>
<ul>
<li class="chapter" data-level="5.1" data-path="module-5---basic-data-preparation.html"><a href="module-5---basic-data-preparation.html#overview-2"><i class="fa fa-check"></i><b>5.1</b> Overview</a></li>
<li class="chapter" data-level="5.2" data-path="module-5---basic-data-preparation.html"><a href="module-5---basic-data-preparation.html#m5l1---data-prep---intro"><i class="fa fa-check"></i><b>5.2</b> M5L1 - Data Prep - Intro</a>
<ul>
<li class="chapter" data-level="5.2.1" data-path="module-5---basic-data-preparation.html"><a href="module-5---basic-data-preparation.html#data-preparation"><i class="fa fa-check"></i><b>5.2.1</b> Data Preparation</a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="module-5---basic-data-preparation.html"><a href="module-5---basic-data-preparation.html#m5l2---outlier-detection"><i class="fa fa-check"></i><b>5.3</b> M5L2 - Outlier Detection</a></li>
<li class="chapter" data-level="5.4" data-path="module-5---basic-data-preparation.html"><a href="module-5---basic-data-preparation.html#m5l3---dealing-with-outliers"><i class="fa fa-check"></i><b>5.4</b> M5L3 - Dealing with Outliers</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="module-6---change-detection.html"><a href="module-6---change-detection.html"><i class="fa fa-check"></i><b>6</b> Module 6 - Change Detection</a>
<ul>
<li class="chapter" data-level="6.1" data-path="module-6---change-detection.html"><a href="module-6---change-detection.html#overview-3"><i class="fa fa-check"></i><b>6.1</b> Overview</a></li>
<li class="chapter" data-level="6.2" data-path="module-6---change-detection.html"><a href="module-6---change-detection.html#m6l1---intro-to-change-detection"><i class="fa fa-check"></i><b>6.2</b> M6L1 - Intro to Change Detection</a></li>
<li class="chapter" data-level="6.3" data-path="module-6---change-detection.html"><a href="module-6---change-detection.html#m6l2---cumulative-sum-cusum-for-change-detection"><i class="fa fa-check"></i><b>6.3</b> M6L2 - Cumulative Sum (CUSUM) for Change Detection</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="module-7---time-series-models.html"><a href="module-7---time-series-models.html"><i class="fa fa-check"></i><b>7</b> Module 7 - Time Series Models</a>
<ul>
<li class="chapter" data-level="7.1" data-path="module-7---time-series-models.html"><a href="module-7---time-series-models.html#m7l1---introduction-to-exponential-smoothing"><i class="fa fa-check"></i><b>7.1</b> M7L1 - Introduction to Exponential Smoothing</a>
<ul>
<li class="chapter" data-level="7.1.1" data-path="module-7---time-series-models.html"><a href="module-7---time-series-models.html#time-series-data"><i class="fa fa-check"></i><b>7.1.1</b> Time Series Data</a></li>
<li class="chapter" data-level="7.1.2" data-path="module-7---time-series-models.html"><a href="module-7---time-series-models.html#exponential-smoothing-method"><i class="fa fa-check"></i><b>7.1.2</b> Exponential Smoothing Method</a></li>
</ul></li>
<li class="chapter" data-level="7.2" data-path="module-7---time-series-models.html"><a href="module-7---time-series-models.html#m7l2---trend-and-cyclic-effects"><i class="fa fa-check"></i><b>7.2</b> M7L2 - Trend and Cyclic Effects</a>
<ul>
<li class="chapter" data-level="7.2.1" data-path="module-7---time-series-models.html"><a href="module-7---time-series-models.html#exponential-smoothing-method-1"><i class="fa fa-check"></i><b>7.2.1</b> Exponential Smoothing Method</a></li>
<li class="chapter" data-level="7.2.2" data-path="module-7---time-series-models.html"><a href="module-7---time-series-models.html#trends"><i class="fa fa-check"></i><b>7.2.2</b> Trends</a></li>
<li class="chapter" data-level="7.2.3" data-path="module-7---time-series-models.html"><a href="module-7---time-series-models.html#cylic-patterns"><i class="fa fa-check"></i><b>7.2.3</b> Cylic Patterns</a></li>
<li class="chapter" data-level="7.2.4" data-path="module-7---time-series-models.html"><a href="module-7---time-series-models.html#models"><i class="fa fa-check"></i><b>7.2.4</b> Models</a></li>
</ul></li>
<li class="chapter" data-level="7.3" data-path="module-7---time-series-models.html"><a href="module-7---time-series-models.html#m7l3---exponential-smoothing---what-the-name-means"><i class="fa fa-check"></i><b>7.3</b> M7L3 - Exponential Smoothing - What the Name Means</a>
<ul>
<li class="chapter" data-level="7.3.1" data-path="module-7---time-series-models.html"><a href="module-7---time-series-models.html#basic-single-exponential-smoothing"><i class="fa fa-check"></i><b>7.3.1</b> Basic single exponential smoothing</a></li>
</ul></li>
<li class="chapter" data-level="7.4" data-path="module-7---time-series-models.html"><a href="module-7---time-series-models.html#m7l4---forcasting"><i class="fa fa-check"></i><b>7.4</b> M7L4 - Forcasting</a>
<ul>
<li class="chapter" data-level="7.4.1" data-path="module-7---time-series-models.html"><a href="module-7---time-series-models.html#forecasting"><i class="fa fa-check"></i><b>7.4.1</b> Forecasting</a></li>
<li class="chapter" data-level="7.4.2" data-path="module-7---time-series-models.html"><a href="module-7---time-series-models.html#forecasting-with-trend"><i class="fa fa-check"></i><b>7.4.2</b> Forecasting with Trend</a></li>
<li class="chapter" data-level="7.4.3" data-path="module-7---time-series-models.html"><a href="module-7---time-series-models.html#forecasting-with-multiplicative-seasonality"><i class="fa fa-check"></i><b>7.4.3</b> Forecasting with Multiplicative Seasonality</a></li>
<li class="chapter" data-level="7.4.4" data-path="module-7---time-series-models.html"><a href="module-7---time-series-models.html#future"><i class="fa fa-check"></i><b>7.4.4</b> Future</a></li>
</ul></li>
<li class="chapter" data-level="7.5" data-path="module-7---time-series-models.html"><a href="module-7---time-series-models.html#m7l5---arima"><i class="fa fa-check"></i><b>7.5</b> M7L5 - ARIMA</a>
<ul>
<li class="chapter" data-level="7.5.1" data-path="module-7---time-series-models.html"><a href="module-7---time-series-models.html#arima"><i class="fa fa-check"></i><b>7.5.1</b> ARIMA</a></li>
<li class="chapter" data-level="7.5.2" data-path="module-7---time-series-models.html"><a href="module-7---time-series-models.html#part-i---differences"><i class="fa fa-check"></i><b>7.5.2</b> Part I - Differences</a></li>
<li class="chapter" data-level="7.5.3" data-path="module-7---time-series-models.html"><a href="module-7---time-series-models.html#part-ii---autoregression"><i class="fa fa-check"></i><b>7.5.3</b> Part II - Autoregression</a></li>
<li class="chapter" data-level="7.5.4" data-path="module-7---time-series-models.html"><a href="module-7---time-series-models.html#part-iii---moving-average"><i class="fa fa-check"></i><b>7.5.4</b> Part III - Moving Average</a></li>
</ul></li>
<li class="chapter" data-level="7.6" data-path="module-7---time-series-models.html"><a href="module-7---time-series-models.html#m7l6---garch"><i class="fa fa-check"></i><b>7.6</b> M7L6 - GARCH</a>
<ul>
<li class="chapter" data-level="7.6.1" data-path="module-7---time-series-models.html"><a href="module-7---time-series-models.html#variance"><i class="fa fa-check"></i><b>7.6.1</b> Variance</a></li>
<li class="chapter" data-level="7.6.2" data-path="module-7---time-series-models.html"><a href="module-7---time-series-models.html#variance-estimation"><i class="fa fa-check"></i><b>7.6.2</b> Variance Estimation</a></li>
<li class="chapter" data-level="7.6.3" data-path="module-7---time-series-models.html"><a href="module-7---time-series-models.html#summary-6"><i class="fa fa-check"></i><b>7.6.3</b> Summary</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="8" data-path="module-8---basics-of-regression.html"><a href="module-8---basics-of-regression.html"><i class="fa fa-check"></i><b>8</b> Module 8 - Basics of Regression</a>
<ul>
<li class="chapter" data-level="8.1" data-path="module-8---basics-of-regression.html"><a href="module-8---basics-of-regression.html#m8l1---introduction-to-regression"><i class="fa fa-check"></i><b>8.1</b> M8L1 - Introduction to Regression</a>
<ul>
<li class="chapter" data-level="8.1.1" data-path="module-8---basics-of-regression.html"><a href="module-8---basics-of-regression.html#regression"><i class="fa fa-check"></i><b>8.1.1</b> Regression</a></li>
<li class="chapter" data-level="8.1.2" data-path="module-8---basics-of-regression.html"><a href="module-8---basics-of-regression.html#simple-linear-regression-slr"><i class="fa fa-check"></i><b>8.1.2</b> Simple Linear Regression (SLR)</a></li>
<li class="chapter" data-level="8.1.3" data-path="module-8---basics-of-regression.html"><a href="module-8---basics-of-regression.html#summary-7"><i class="fa fa-check"></i><b>8.1.3</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="8.2" data-path="module-8---basics-of-regression.html"><a href="module-8---basics-of-regression.html#m8l2---maximum-likelihood-and-information-criteria"><i class="fa fa-check"></i><b>8.2</b> M8L2 - Maximum Likelihood and Information Criteria</a></li>
<li class="chapter" data-level="8.3" data-path="module-8---basics-of-regression.html"><a href="module-8---basics-of-regression.html#m8l3---using-regression"><i class="fa fa-check"></i><b>8.3</b> M8L3 - Using Regression</a></li>
<li class="chapter" data-level="8.4" data-path="module-8---basics-of-regression.html"><a href="module-8---basics-of-regression.html#m8l4---causation-vs.-correlation"><i class="fa fa-check"></i><b>8.4</b> M8L4 - Causation vs. Correlation</a></li>
<li class="chapter" data-level="8.5" data-path="module-8---basics-of-regression.html"><a href="module-8---basics-of-regression.html#m8l5---transformations-and-interactions"><i class="fa fa-check"></i><b>8.5</b> M8L5 - Transformations and Interactions</a></li>
<li class="chapter" data-level="8.6" data-path="module-8---basics-of-regression.html"><a href="module-8---basics-of-regression.html#m8l6---output"><i class="fa fa-check"></i><b>8.6</b> M8L6 - Output</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="appendix-a-glossary.html"><a href="appendix-a-glossary.html"><i class="fa fa-check"></i><b>9</b> Appendix A: Glossary</a>
<ul>
<li class="chapter" data-level="9.1" data-path="appendix-a-glossary.html"><a href="appendix-a-glossary.html#basic-machine-learning"><i class="fa fa-check"></i><b>9.1</b> Basic Machine Learning</a></li>
</ul></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Course Notes - Introduction to Analytics Modeling</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="module-4---clustering" class="section level1 hasAnchor" number="4">
<h1><span class="header-section-number">4</span> Module 4 - Clustering<a href="module-4---clustering.html#module-4---clustering" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<div id="overview-1" class="section level2 hasAnchor" number="4.1">
<h2><span class="header-section-number">4.1</span> Overview<a href="module-4---clustering.html#overview-1" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Module 4 will continue with basic machine learning algorithms.
The focus will be on clustering models.
The modules will cover couple of cross-cutting concepts, including distance norms, and k-means clustering.</p>
<p>Additional References:</p>
<p><span class="citation"><a href="#ref-wikibookskmeans">[2]</a></span>. <a href="https://en.wikibooks.org/wiki/Data_Mining_Algorithms_In_R/Clustering/K-Means">Data Mining Algorithms In R/Clustering/K-Means</a></p>
</div>
<div id="m4l1---introduction-to-clustering" class="section level2 hasAnchor" number="4.2">
<h2><span class="header-section-number">4.2</span> M4L1 - Introduction to Clustering<a href="module-4---clustering.html#m4l1---introduction-to-clustering" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p><strong>Clustering:</strong> An unsupervised machine learning technique designed to group unlabeled examples based on their similarity to each other.</p>
<ul>
<li>Grouping data points</li>
<li><em>Important to note: If the examples are labeled, the grouping is called classification</em></li>
</ul>
<p>Examples of Clustering:</p>
<ul>
<li>Targeted marketing/market segmentation
<ul>
<li>Potential customers need a message that would be most likely to encourage them to buy</li>
</ul></li>
<li>For example, if we were selling a SUV:
<ul>
<li>Size</li>
<li>Price</li>
<li>Versatility</li>
<li>Coolness</li>
</ul></li>
<li>Each set of people would be a cluster</li>
<li>We would try to use data to split consumers into sets to discover what marketing they should be shown</li>
<li>You can examine a cluster and it may not always be correct, which can help you find a meaningful cluster in your data
<ul>
<li>For example, we did not consider gas mileage</li>
</ul></li>
<li>Other examples:
<ul>
<li>Targeted marketing/market segmentation</li>
<li>Personalized medicine</li>
<li>Locating facilities - Look at where people live and provide a police station for each cluster</li>
<li>Image analysis - CAPCHA</li>
<li>Initial data investigation</li>
</ul></li>
</ul>
</div>
<div id="m4l2---distance-norms" class="section level2 hasAnchor" number="4.3">
<h2><span class="header-section-number">4.3</span> M4L2 - Distance Norms<a href="module-4---clustering.html#m4l2---distance-norms" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>The choice of distance measures is important in clustering.
Distance measures define how the similarity of the two element are calculated and influences the shape of the clusters.</p>
<p><strong>Euclidean (straight-line) distance:</strong></p>
<ul>
<li>Distance in Euclidean space by length of straight line segment between two points
<span class="math display">\[
distance = \sqrt{\sum^n_{i=1}(x_i - y_i)^2} = \sqrt{(x_1-y_1)^2+(x_2-y_2)^2}
\]</span></li>
</ul>
<p><strong>Rectilinear (Manhattan) Distance:</strong></p>
<ul>
<li>Commonly used in city planning with a grid, hence Manhattan term
<span class="math display">\[
distance = \sum^n_{i=1} |x_i-y_i| =  |x_1-y_1| + |x_2-y_2|
\]</span></li>
</ul>
<p><strong>Minkowski (p-norm) Distance:</strong></p>
<ul>
<li>We can describe both euclidean (p=2) and rectilinear (p=1) distance with p-norm (or Minkowski) distance
<span class="math display">\[
distance = \sqrt[p]{\sum^n_{i=1} |x_i-y_i|^p} = \sqrt[p]{|x_1-y_1|^p + |x_2-y_2|^p}
\]</span></li>
</ul>
<p>The most common values for p include 1, 2, and <span class="math inline">\(\infty\)</span> (<span class="math inline">\(\infty\)</span>-norm distance).</p>
<p><strong>Infinity-Norm Distance (<span class="math inline">\(\infty\)</span>-norm):</strong></p>
<p>The infinity norm simply measures how large the vector is by the magnitude of its largest entry.
Simply put, it is the largest of a set of numbers in an absolute of values (the biggest).</p>
<p><span class="math display">\[
distance = \lim_{p\to\infty} \sqrt[\infty]{\sum^n_{i=1} |x_i-y_i|^{\infty}}
\]</span>
The largest value for <span class="math inline">\(\infty\)</span> (assume p is 8) is dominated by the largest power.
The term to the 7th power would be small compared to the 8th power.
This means considering distance, the sum of terms is equal to the largest <span class="math inline">\(|x_i-y_i|\)</span> to the infinity power.</p>
<p><em>Note: Should include the limit to infinity, but for simplicity the equations do not all include the limit.</em>
<span class="math display">\[
distance = \lim_{p\to\infty} \sqrt[\infty]{\sum^n_{i=1} |x_i-y_i|^{\infty}} = \sqrt[\infty]{\max_i |x_i-y_i|^{\infty}}=\max_i |x_i-y_i|
\]</span></p>
</div>
<div id="m4l3---k-means-clustering" class="section level2 hasAnchor" number="4.4">
<h2><span class="header-section-number">4.4</span> M4L3 - K-Means Clustering<a href="module-4---clustering.html#m4l3---k-means-clustering" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>The K-Means algorithm is a popular technique of representative-based clustering.
K-Means is a simple learning algorithm for clustering analysis.
The goal of K-Means algorithm is to find the best division of n entities in k groups, so that the total distance between the group’s members and its corresponding centroid, representative of the group, is minimized <span class="citation"><a href="#ref-wikibookskmeans">[2]</a></span>.</p>
<p>Consider the K-Means algorithm defined as:</p>
<p><span class="math display">\[
\min_{y,z} \sum_i \sum_k y_{ik} \sqrt{\sum_j (x_{ij}-z_{jk})^2}
\]</span>
The algorithm is subject to <span class="math inline">\(\sum_k y_{ik} = 1\)</span> for each <code>i</code> where:</p>
<ul>
<li><span class="math inline">\(x_{ij}\)</span> is attribute <code>j</code> of data point <code>i</code></li>
<li><span class="math inline">\(y_{ik}\)</span> is 1 if data point <code>i</code> is in cluster k, 0 if not</li>
<li><span class="math inline">\(z_{jk}\)</span> is coordinate <code>j</code> of cluster center <code>k</code></li>
</ul>
<p>Adds up all data points to cluster centers but only when the data point is in the cluster.</p>
<ol start="0" style="list-style-type: decimal">
<li>Pick <code>k</code> cluster centers within range of data (e.g., Pick 3 points, <code>k=3</code>, where each point is a cluster center)</li>
<li>Assign each data point to nearest cluster center</li>
<li>Recalculate cluster centers (centroids of the data points in the cluster)</li>
</ol>
<p>This could result in new cluster centers with cluster points that are more applicable for another cluster.
There is an iterative process for 1 and 2 that are repeated until there are no changes.
Stops when no data points change clusters.</p>
<p><strong>K-Means Algorithm Overview:</strong></p>
<ul>
<li>Machine Learning</li>
<li>Heuristic - Fast, good, but not guaranteed to find absolute best solution</li>
<li>Expectation-Maximization (EM) Algorithm
<ul>
<li>Maximizing the negative distance to a cluster center</li>
</ul></li>
</ul>
</div>
<div id="m4l4---practical-details-for-k-means" class="section level2 hasAnchor" number="4.5">
<h2><span class="header-section-number">4.5</span> M4L4 - Practical Details for K-Means<a href="module-4---clustering.html#m4l4---practical-details-for-k-means" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Using the K-Means algorithm in practice</p>
<div id="summary-3" class="section level3 hasAnchor" number="4.5.1">
<h3><span class="header-section-number">4.5.1</span> Summary<a href="module-4---clustering.html#summary-3" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<ul>
<li><strong>Handling Outliers:</strong> K-means will assign outliers to the nearest cluster, but this can distort results. While one option is to remove outliers, a more thoughtful approach is to investigate their significance and implications for your analysis.</li>
<li><strong>Algorithm Limitations:</strong> K-means is a heuristic, meaning it’s not guaranteed to find the best clustering but is efficient and often finds good solutions. To improve results, it’s advised to run k-means multiple times with different initial cluster centers and compare the outcomes.</li>
<li><strong>Determining the Number of Clusters:</strong> The number of clusters (k) can be optimized by running the algorithm with different k values and using an “elbow diagram” to identify where increasing the number of clusters no longer significantly improves the solution. However, practical considerations should also guide this choice, depending on the context.</li>
<li><strong>Balancing Science and Art:</strong> The lecture emphasizes the importance of blending data science with the “art” of analytics, where understanding the situation and making informed decisions can provide greater value than merely running algorithms.</li>
</ul>
</div>
</div>
<div id="m4l5---clustering-for-prediction" class="section level2 hasAnchor" number="4.6">
<h2><span class="header-section-number">4.6</span> M4L5 - Clustering for Prediction<a href="module-4---clustering.html#m4l5---clustering-for-prediction" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<div id="summary-4" class="section level3 hasAnchor" number="4.6.1">
<h3><span class="header-section-number">4.6.1</span> Summary<a href="module-4---clustering.html#summary-4" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<ul>
<li><strong>Clustering Recap:</strong> Clustering involves grouping data points based on their similarity and proximity. The k-means heuristic is a common method for finding good clusterings.</li>
<li><strong>Predictive Clustering:</strong> K-means clustering can be used predictively by determining which cluster a new data point should belong to, typically by finding the closest cluster center.</li>
<li><strong>Handling New Data Points:</strong> If a new data point falls within an existing cluster, it is straightforward to assign it to that cluster. If not, the point is assigned to the nearest cluster center.</li>
<li><strong>Voronoi Diagrams:</strong> The space around each cluster center can be divided into regions, where each region represents the area closer to that center than to any other. This is visualized using a Voronoi diagram.</li>
<li><strong>Historical Context:</strong> Voronoi diagrams have been used historically, including in the analysis of a cholera outbreak in London over 150 years ago, and by mathematicians like Rene Descartes in the 1600s.</li>
<li><strong>Old Ideas in Analytics:</strong> Some effective analytical techniques, like Voronoi diagrams, are not new but have been around for a long time and remain valuable.</li>
</ul>
</div>
</div>
<div id="m4l6---clustering-v.-classification" class="section level2 hasAnchor" number="4.7">
<h2><span class="header-section-number">4.7</span> M4L6 - Clustering v. Classification<a href="module-4---clustering.html#m4l6---clustering-v.-classification" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<div id="summary-5" class="section level3 hasAnchor" number="4.7.1">
<h3><span class="header-section-number">4.7.1</span> Summary<a href="module-4---clustering.html#summary-5" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<ul>
<li><p><strong>Classification Models:</strong> These involve a set of data points where both their attributes and correct groupings (responses) are known. For example, in loan application data, we know whether applicants repaid their loans (blue) or not (red). Classification models use both attributes and known responses to classify new data points. This process is known as supervised learning because it uses observed responses to guide the model.</p></li>
<li><p><strong>Clustering Models:</strong> In contrast, clustering models start with a set of data points where only the attributes are known, and the correct groupings are not known. The model must determine how to group the data points based solely on their attributes. This is known as unsupervised learning because there are no observed responses to guide the model.</p></li>
</ul>
<p>Supervised learning is more common in analytics (such as classification) but unsupervised learning (such as clustering) is also a valuable tool.</p>

</div>
</div>
</div>
<h3>References</h3>
<div id="refs" class="references csl-bib-body" entry-spacing="0">
<div id="ref-wikibookskmeans" class="csl-entry">
<div class="csl-left-margin">[2] </div><div class="csl-right-inline">Wikibooks, <span>“Data mining algorithms in r/clustering/k-means.”</span> <a href="http://en.wikipedia.org/w/index.php?title=K-means%20clustering&amp;oldid=1243054475" class="uri">http://en.wikipedia.org/w/index.php?title=K-means%20clustering&amp;oldid=1243054475</a>, 2024.</div>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="module-3---validation.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="module-5---basic-data-preparation.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["ISYE6501-Notes-Fall2024.pdf"],
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
